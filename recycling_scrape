import requests
from bs4 import BeautifulSoup
import csv
import pandas as pd

def initial_parse(page_link):
    html_page = requests.get(page_link)
    soup = BeautifulSoup(html_page.content, 'html.parser')
    #Find Section of website
    section = soup.find('div', class_='list-group geo-major')
    #In the Html code there are two 'divs' titled list-group geo-major
    list_links = section.find_next('div')
    dictionary = {county.a['title'] : county.a['href'] for county in list_links.find_all('li')}
    return dictionary

def get_address(zed):
    html_page = requests.get(zed)
    soup = BeautifulSoup(html_page.content, 'html.parser')

    title = soup.title.contents
    # Find Section of website
    section = soup.find('div', class_='listings')
    check = section.find_all('p', class_= 'condensed-listing alt')
    col_names = ['County','Name of Center', 'City-State','Address','ZipCode']
    df = pd.DataFrame(columns=col_names)
    for i in check:
        name = i.find('span', class_='name').contents
        city_state = i.find('span', class_='city-state').contents
        address = i.find('span', class_='subsidiary').find('span', class_='address').contents
        zip_code = i.find('span', class_='subsidiary').find('span', class_='zipcode').contents
        temp = pd.DataFrame(
                {'County' : title,
                 'Name of Center' : name[0],
                   'City-State': city_state,
                   'Address' : address,
                   'ZipCode' : zip_code
                 }
        )
        df = pd.concat([df, temp]) #TODO read into CONCAT documentaion, get rid of '0,' in every line of csv
    return df

#This is the link I'm scraping from
page_link = 'https://www.recycling-center.org/michigan/'

diction = initial_parse(page_link)
keys = []
counties_url = []
col_names = ['County','Name of Center', 'City-State', 'Address', 'ZipCode']
almost_final = pd.DataFrame(columns=col_names)

for key, urls in diction.items():
    keys.append(key)
    test = 'https://www.recycling-center.org'+urls
    counties_url.append(test)

for x in counties_url:
    temporary = get_address(x)
    almost_final = pd.concat([almost_final, temporary])

recycle_csv = almost_final.to_csv('michigan_recycle.csv', index = True)
